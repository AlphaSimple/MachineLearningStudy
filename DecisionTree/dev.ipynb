{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearningStudy/\n",
      "├── datasets/\n",
      "│   ├── bank-4.zip\n",
      "│   └── car-4.zip\n",
      "├── DecisionTree/\n",
      "│   ├── __init__.py\n",
      "│   ├── dev.ipynb\n",
      "│   └── run.py\n",
      "├── LICENSE\n",
      "├── main.py\n",
      "└── README.md\n"
     ]
    }
   ],
   "source": [
    "from directory_tree import display_tree\n",
    "\n",
    "display_tree('../../MachineLearningStudy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in ../datasets/car-4.zip :\n",
      "data-desc.txt\n",
      "test.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3. read the training data (list or a pandas dataframe)\n",
    "4. explore the data (e.g. print the first few rows, check the shape, check the columns, check the data types)\n",
    "'''\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Path to the dataset zip file\n",
    "dataset_zip_path = '../datasets/car-4.zip'\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(dataset_zip_path, 'r') as dataset_zip_ref:\n",
    "    print(\"Files in\", dataset_zip_path, \":\")\n",
    "    for file_name in dataset_zip_ref.namelist():\n",
    "            if '__MACOSX/' not in file_name:\n",
    "                print(file_name)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| label values\n",
      "\n",
      "unacc, acc, good, vgood\n",
      "\n",
      "| attributes\n",
      "\n",
      "buying:   vhigh, high, med, low.\n",
      "maint:    vhigh, high, med, low.\n",
      "doors:    2, 3, 4, 5more.\n",
      "persons:  2, 4, more.\n",
      "lug_boot: small, med, big.\n",
      "safety:   low, med, high.\n",
      "\n",
      "| columns\n",
      "buying,maint,doors,persons,lug_boot,safety,label\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the zip file\n",
    "with zipfile.ZipFile(dataset_zip_path, 'r') as dataset_zip_ref:\n",
    "    with dataset_zip_ref.open('data-desc.txt') as desc_file:\n",
    "        desc_content = desc_file.read().decode(\"utf-8\")\n",
    "        print(desc_content)\n",
    "        \n",
    "    with dataset_zip_ref.open('train.csv') as train_file:\n",
    "        train_df = pd.read_csv(io.BytesIO(train_file.read()), header=None)\n",
    "        header = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'evaluation']\n",
    "        train_df.columns = header\n",
    "        \n",
    "    with dataset_zip_ref.open('test.csv') as test_file:\n",
    "        test_df = pd.read_csv(io.BytesIO(test_file.read()), header=None)\n",
    "        header = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'evaluation']\n",
    "        test_df.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint  doors persons lug_boot safety evaluation\n",
       "0    low  vhigh      4       4      big    med        acc\n",
       "1    low   high  5more       4      med   high      vgood\n",
       "2  vhigh    med      2       2      big   high      unacc\n",
       "3   high   high      2       2    small   high      unacc\n",
       "4  vhigh    low      3       2      big    low      unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>259</td>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>337</td>\n",
       "      <td>341</td>\n",
       "      <td>344</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying maint doors persons lug_boot safety evaluation\n",
       "count    1000  1000  1000    1000     1000   1000       1000\n",
       "unique      4     4     4       3        3      3          4\n",
       "top     vhigh  high     4       4      big    med      unacc\n",
       "freq      259   255   253     337      341    344        698"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying \n",
      " ['vhigh', 'high', 'med', 'low'] \n",
      "\n",
      "maint \n",
      " ['vhigh', 'high', 'med', 'low'] \n",
      "\n",
      "doors \n",
      " ['2', '3', '4', '5more'] \n",
      "\n",
      "persons \n",
      " ['2', '4', 'more'] \n",
      "\n",
      "lug_boot \n",
      " ['small', 'med', 'big'] \n",
      "\n",
      "safety \n",
      " ['low', 'med', 'high'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in desc_content.splitlines()[:-1]:\n",
    "    if any(attrib in line for attrib in train_df.columns.tolist()[:-1]):\n",
    "        attrib = line.split(':')[0].strip()\n",
    "        values = [value.strip() for value in line.split(':')[1].strip()[:-1].split(',')]\n",
    "        print(attrib, '\\n', values, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, train_df, test_df, desc_content) -> None:\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.desc_content = desc_content\n",
    "        \n",
    "        self.attributes_values_dict = {}\n",
    "        for line in self.desc_content.splitlines()[:-1]:\n",
    "            if any(attrib in line for attrib in self.train_df.columns.tolist()[:-1]):\n",
    "                attrib = line.split(':')[0].strip()\n",
    "                values = [value.strip() for value in line.split(':')[1].strip()[:-1].split(',')]\n",
    "                # print(attrib, '\\n', values, '\\n')\n",
    "                self.attributes_values_dict[attrib] = values\n",
    "                \n",
    "        self.attributes = list(self.attributes_values_dict.keys())\n",
    "        self.label_column = 'evaluation'\n",
    "        \n",
    "        count_down = -1\n",
    "        for line in self.desc_content.splitlines()[:-1]:\n",
    "            if 'label values' in line:\n",
    "                count_down = 2\n",
    "            count_down -= 1\n",
    "            if count_down == 0:\n",
    "                self.label_values = [label_value.strip() for label_value in line.split(',')]\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    \n",
    "    def __init__(self, data=None, parent_node=None, child_nodes=None) -> None:\n",
    "        self.data = data\n",
    "        self.parent_node = parent_node\n",
    "        \n",
    "        # it is a dict of edges as keys and child TreeNode-s as values\n",
    "        self.child_nodes = child_nodes\n",
    "        \n",
    "    def create_child_node(self, edge, child_node):\n",
    "        # adds child node into this node and returns that child node\n",
    "        if self.child_nodes == None:\n",
    "            self.child_nodes = {}\n",
    "        child_node.parent_node = self\n",
    "        self.child_nodes[edge] = child_node\n",
    "\n",
    "class DecisionTreeID3:\n",
    "    \n",
    "    def __init__(self, dataset, gain, depth=-1) -> None:\n",
    "        '''\n",
    "            train_df: train data's pandas dataframe\n",
    "            \n",
    "            depth = -1 means no depth limit set \n",
    "            i.e. depth cut off of 0 will never be reached\n",
    "        '''\n",
    "        self.dataset = dataset\n",
    "        self.gain_name = gain\n",
    "        self.tree = self.id3(self.dataset.train_df, self.dataset.attributes, depth=depth)\n",
    "    \n",
    "    def entropy(self, df):\n",
    "        H = 0\n",
    "        if len(df) == 0:\n",
    "            return H\n",
    "        for label_value in self.dataset.label_values:\n",
    "            p = len(df[df['evaluation'] == label_value])/len(df)\n",
    "            if p > 0:\n",
    "                H -= p*log2(p)\n",
    "            else:\n",
    "                H -= 0\n",
    "        return H\n",
    "    \n",
    "    def majority_error(self, df):\n",
    "        if len(df) == 0:\n",
    "            return 0\n",
    "        # ME = 1 - (count of most common label value / total count of labels)\n",
    "        ME = 1 - (df['evaluation'].value_counts().max()/len(df))\n",
    "        return ME\n",
    "    \n",
    "    def gini_index(self, df):\n",
    "        GI = 1\n",
    "        if len(df) == 0:\n",
    "            return GI\n",
    "        for label_value in self.dataset.label_values:\n",
    "            p = len(df[df['evaluation'] == label_value])/len(df)\n",
    "            GI -= p**2\n",
    "        return GI\n",
    "    \n",
    "    def gain(self, df, attribute, impurity_measure):\n",
    "        H_s = impurity_measure(df)\n",
    "        gain = H_s\n",
    "        for value in self.dataset.attributes_values_dict[attribute]:\n",
    "            filtered_df = df[df[attribute] == value]\n",
    "            H_sv = impurity_measure(filtered_df)\n",
    "            weighted_term = (len(filtered_df)/len(df))*H_sv\n",
    "            gain -= weighted_term\n",
    "        return gain\n",
    "    \n",
    "    def best_split_attribute(self, train_df, attributes):\n",
    "        gains_of_attributes = []\n",
    "        if self.gain_name == 'entropy':\n",
    "            for attribute in attributes:\n",
    "                gains_of_attributes.append([attribute, self.gain(train_df, attribute, self.entropy)])\n",
    "        elif self.gain_name == 'majority_error':\n",
    "            for attribute in attributes:\n",
    "                gains_of_attributes.append([attribute, self.gain(train_df, attribute, self.majority_error)])\n",
    "        elif self.gain_name == 'gini_index':\n",
    "            for attribute in attributes:\n",
    "                gains_of_attributes.append([attribute, self.gain(train_df, attribute, self.gini_index)])\n",
    "        # return the attribute name with the max gain value of all\n",
    "        return max(gains_of_attributes, key=lambda x: x[1])[0]\n",
    "    \n",
    "    def id3(self, train_df, attributes, depth):\n",
    "        if len(train_df['evaluation'].unique()) == 1:\n",
    "            label = train_df['evaluation'].unique()[0]\n",
    "            return TreeNode(label)\n",
    "        elif attributes == []:\n",
    "            return TreeNode(data=train_df['evaluation'].value_counts().idxmax())\n",
    "        elif depth == 0:\n",
    "            return TreeNode(data=train_df['evaluation'].value_counts().idxmax())\n",
    "        else:\n",
    "            root = TreeNode()\n",
    "            A = self.best_split_attribute(train_df, attributes)\n",
    "            root.data = A\n",
    "            for value in self.dataset.attributes_values_dict[A]:\n",
    "                filtered_df = train_df[train_df[A] == value]\n",
    "                if len(filtered_df) == 0:\n",
    "                    child_node = TreeNode(data=train_df['evaluation'].value_counts().idxmax())\n",
    "                    root.create_child_node(value, child_node=child_node)\n",
    "                else:\n",
    "                    new_attributes = attributes.copy()\n",
    "                    new_attributes.remove(A)\n",
    "                    child_node = self.id3(filtered_df, new_attributes, depth-1)\n",
    "                    root.create_child_node(value, child_node=child_node)\n",
    "            return root\n",
    "    \n",
    "    def tree_travel(self, sample_dict, tree):\n",
    "        if tree.child_nodes == None:\n",
    "            return tree.data\n",
    "        else:\n",
    "            root = tree\n",
    "            child_node = root.child_nodes[sample_dict[root.data]]\n",
    "            return self.tree_travel(sample_dict, child_node)\n",
    "    \n",
    "    def prediction(self, sample):\n",
    "        sample_dict = {}\n",
    "        for index, value in enumerate(sample):\n",
    "            sample_dict[(self.dataset.attributes+[self.dataset.label_column])[index]] = value\n",
    "        \n",
    "        root = self.tree\n",
    "        return self.tree_travel(sample_dict, root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataset object\n",
    "dataset = Dataset(train_df, test_df, desc_content)\n",
    "\n",
    "# creating Decision Tree on `dataset`\n",
    "dt = DecisionTreeID3(dataset, gain='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unacc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_df.iloc[2].tolist()\n",
    "\n",
    "dt.prediction(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prediction error on Train set = 100.00 %\n"
     ]
    }
   ],
   "source": [
    "count_predict = 0\n",
    "count_correct_predict = 0\n",
    "for index in range(len(train_df)):\n",
    "    sample = train_df.iloc[index].tolist()\n",
    "    label_predict = dt.prediction(sample)\n",
    "    count_predict += 1\n",
    "    if label_predict == sample[-1]:\n",
    "        count_correct_predict += 1\n",
    "        \n",
    "print(f'Average prediction error on Train set = {count_correct_predict*100/count_predict:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prediction error on Test set = 60.71 %\n"
     ]
    }
   ],
   "source": [
    "count_predict = 0\n",
    "count_correct_predict = 0\n",
    "for index in range(len(test_df)):\n",
    "    sample = test_df.iloc[index].tolist()\n",
    "    label_predict = dt.prediction(sample)\n",
    "    count_predict += 1\n",
    "    if label_predict == sample[-1]:\n",
    "        count_correct_predict += 1\n",
    "        \n",
    "print(f'Average prediction error on Test set = {count_correct_predict*100/count_predict:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average prediction error on Train set = 100.00 %\n",
      "Average prediction error on Test set = 90.66 %\n"
     ]
    }
   ],
   "source": [
    "# create Dataset object\n",
    "dataset = Dataset(train_df, test_df, desc_content)\n",
    "\n",
    "# learning Decision Tree on `dataset`\n",
    "dt = DecisionTreeID3(dataset, gain='majority_error', depth=-1)\n",
    "\n",
    "# Train pedictions\n",
    "count_predict = 0\n",
    "count_correct_predict = 0\n",
    "for index in range(len(train_df)):\n",
    "    sample = train_df.iloc[index].tolist()\n",
    "    label_predict = dt.prediction(sample)\n",
    "    count_predict += 1\n",
    "    if label_predict == sample[-1]:\n",
    "        count_correct_predict += 1\n",
    "        \n",
    "print(f'Average prediction error on Train set = {count_correct_predict*100/count_predict:.2f} %')\n",
    "\n",
    "# Test predictions\n",
    "count_predict = 0\n",
    "count_correct_predict = 0\n",
    "for index in range(len(test_df)):\n",
    "    sample = test_df.iloc[index].tolist()\n",
    "    label_predict = dt.prediction(sample)\n",
    "    count_predict += 1\n",
    "    if label_predict == sample[-1]:\n",
    "        count_correct_predict += 1\n",
    "        \n",
    "print(f'Average prediction error on Test set = {count_correct_predict*100/count_predict:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "(a) [15 points] Implement the ID3 algorithm that supports, information gain, \n",
    "majority error and gini index to select attributes for data splits. Besides, your ID3\n",
    "should allow users to set the maximum tree depth. Note: you do not need to\n",
    "convert categorical attributes into binary ones and your tree can be wide here.\n",
    "\n",
    "(b) [10 points] Use your implemented algorithm to learn decision trees from the\n",
    "training data. Vary the maximum tree depth from 1 to 6 — for each setting,\n",
    "run your algorithm to learn a decision tree, and use the tree to predict both the\n",
    "training and test examples. Note that if your tree cannot grow up to 6 levels, you\n",
    "can stop at the maximum level. Report in a table the average prediction errors\n",
    "on each dataset when you use information gain, majority error and gini index\n",
    "heuristics, respectively.\n",
    "\n",
    "(c) [5 points] What can you conclude by comparing the training errors and the test\n",
    "errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predicts(dt):\n",
    "    # Train predictions\n",
    "    count_predict = 0\n",
    "    count_wrong_predict = 0\n",
    "    for index in range(len(train_df)):\n",
    "        sample = train_df.iloc[index].tolist()\n",
    "        label_predict = dt.prediction(sample)\n",
    "        count_predict += 1\n",
    "        if label_predict == sample[-1]:\n",
    "            count_wrong_predict += 1\n",
    "    \n",
    "    # print(f'Average prediction error on Train set = {count_wrong_predict*100/count_predict:.2f} %')\n",
    "    \n",
    "    if gain_name == 'entropy':\n",
    "        errors = acc_using_h\n",
    "    elif gain_name == 'majority_error':\n",
    "        errors = acc_using_me\n",
    "    elif gain_name == 'gini_index':\n",
    "        errors = acc_using_gi\n",
    "    \n",
    "    errors['train'].append(round(count_wrong_predict*100/count_predict,2))\n",
    "\n",
    "\n",
    "def test_predicts(dt):\n",
    "    # Test predictions\n",
    "    count_predict = 0\n",
    "    count_wrong_predict = 0\n",
    "    for index in range(len(test_df)):\n",
    "        sample = test_df.iloc[index].tolist()\n",
    "        label_predict = dt.prediction(sample)\n",
    "        count_predict += 1\n",
    "        if label_predict == sample[-1]:\n",
    "            count_wrong_predict += 1\n",
    "    \n",
    "    # print(f'Average prediction error on Train set = {count_wrong_predict*100/count_predict:.2f} %')\n",
    "    \n",
    "    if gain_name == 'entropy':\n",
    "        errors = acc_using_h\n",
    "    elif gain_name == 'majority_error':\n",
    "        errors = acc_using_me\n",
    "    elif gain_name == 'gini_index':\n",
    "        errors = acc_using_gi\n",
    "    \n",
    "    errors['test'].append(round(count_wrong_predict*100/count_predict,2))\n",
    "\n",
    "\n",
    "acc_using_h = {'train':[], 'test':[]}\n",
    "acc_using_me = {'train':[], 'test':[]}\n",
    "acc_using_gi = {'train':[], 'test':[]}\n",
    "\n",
    "# create Dataset object\n",
    "dataset = Dataset(train_df, test_df, desc_content)\n",
    "\n",
    "for gain_name in ['entropy', 'majority_error', 'gini_index']:\n",
    "    for depth in range(1,6+1):\n",
    "        # learning Decision Tree on `dataset`\n",
    "        dt = DecisionTreeID3(dataset, gain=gain_name, depth=depth)\n",
    "        \n",
    "        # Train predictions\n",
    "        train_predicts(dt)\n",
    "        \n",
    "        # Test predictions\n",
    "        test_predicts(dt)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy\n",
      "--------------------\n",
      "\n",
      "On training set -\n",
      "\n",
      "Entropy          - 69.8   69.8   70.0   76.2   83.1   100.0\n",
      "Majority Error   - 69.8   69.9   81.1   90.3   97.1   100.0\n",
      "Gini Index       - 69.8   69.9   72.3   81.7   91.1   100.0\n",
      "\n",
      "On test set -\n",
      "\n",
      "Entropy          - 70.33  70.33  68.13  64.56  60.71  60.71\n",
      "Majority Error   - 70.33  68.41  77.61  83.79  90.66  90.66\n",
      "Gini Index       - 70.33  68.41  71.29  72.53  77.47  77.47\n"
     ]
    }
   ],
   "source": [
    "print('Prediction Accuracy\\n--------------------\\n')\n",
    "\n",
    "print('On training set -\\n')\n",
    "print('Entropy'+10*' '+'-', '   '.join(str(err) for err in acc_using_h['train']))\n",
    "print('Majority Error'+3*' '+'-', '   '.join(str(err) for err in acc_using_me['train']))\n",
    "print('Gini Index'+7*' '+'-', '   '.join(str(err) for err in acc_using_gi['train']))\n",
    "\n",
    "print()\n",
    "\n",
    "print('On test set -\\n')\n",
    "print('Entropy'+10*' '+'-', '  '.join(str(err) for err in acc_using_h['test']))\n",
    "print('Majority Error'+3*' '+'-', '  '.join(str(err) for err in acc_using_me['test']))\n",
    "print('Gini Index'+7*' '+'-', '  '.join(str(err) for err in acc_using_gi['test']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
